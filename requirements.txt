# Python 3.12 + CUDA 11.8 compatible stack for GTX 1080 (Pascal sm_61)
# PyTorch 2.2.2 is the last version with CUDA 11.8 wheel support
torch==2.2.2
torchvision==0.17.2
torchaudio==2.2.2

# Transformers 4.38.x avoids dtype kwarg bug in Qwen2ForCausalLM.__init__
transformers>=4.38.0,<4.46.0
huggingface-hub>=0.20.0
accelerate>=0.27.0

# bitsandbytes 0.43.x supports CUDA 11.8 and Python 3.12
# Note: 4-bit quantization requires sm_75+ (Turing/Ampere), so GTX 1080 will use FP16 fallback
bitsandbytes>=0.43.0,<0.44.0

# timm for DeiT vision encoder
timm>=0.9.0

datasets>=2.14.0
pillow>=10.0.0
pandas>=2.0.0
numpy>=1.24.0,<2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
wandb>=0.15.0
pyyaml>=6.0
requests>=2.31.0
scipy>=1.11.0
scikit-learn>=1.3.0
